{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f3db02",
   "metadata": {
    "id": "44f3db02"
   },
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup \n",
    "import pandas as pd\n",
    "import numpy\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8348be",
   "metadata": {
    "id": "4b8348be"
   },
   "source": [
    "# Collect hotel list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e0d3cd",
   "metadata": {
    "id": "5ab95809"
   },
   "source": [
    "## Quarantine hotels list\n",
    "Hotels with customer reviews that contain the word \"quarantine\".\n",
    "Collected from here: https://en.tripadvisor.com.hk/Search?q=quarantine&searchSessionId=2D417296DF5780B246EEC73E707A39821650210061193ssid&searchNearby=false&geo=294217&sid=10B3B148392F4C5D87D196FC4E0025751650210149092&blockRedirect=true&ssrc=h&rf=1\n",
    "\n",
    "## Non-Quarantine hotel list\n",
    "Full hotels list collected from here:\n",
    "https://en.tripadvisor.com.hk/SmartDeals-g294217-Hong_Kong-Hotel-Deals.html\n",
    "\n",
    "Then, excluded those hotels that are in the Quarantine hotels list.\n",
    "\n",
    "Next, randomly picked 96 hotels from this list for scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de07243",
   "metadata": {
    "id": "7de07243"
   },
   "source": [
    "# Code for scraping Travel Safe During COVID-19 section for each hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2cd235",
   "metadata": {
    "id": "2e2cd235"
   },
   "outputs": [],
   "source": [
    "def scrape_COVID19 (readFileName, sheetName, outputName):\n",
    "\n",
    "    df = pd.read_excel(readFileName, sheet_name=sheetName)\n",
    "\n",
    "\n",
    "    ### ============== try first two as example ===============\n",
    "\n",
    "    #hotelNames = df['hotel name'][0:4].tolist()\n",
    "    #hotelURLs = df['hotel URL'][0:4].tolist()\n",
    "    #hotelIDs = df['hotel ID'][0:4].tolist()\n",
    "\n",
    "\n",
    "    #### ================ run all ===============\n",
    "    hotelNames = df['hotel name']\n",
    "    hotelURLs = df['hotel URL']\n",
    "    hotelIDs = df['hotel ID']\n",
    "    COVID_Expect = []\n",
    "    COVID_Note = []\n",
    "\n",
    "\n",
    "    for hotelURL in hotelURLs:\n",
    "\n",
    "        chromedriver_autoinstaller.install()  \n",
    "        browser = webdriver.Chrome()\n",
    "    \n",
    "        browser.get(hotelURL)\n",
    "        \n",
    "        try:\n",
    "        # click \"Read More\" to expand all text\n",
    "            browser.implicitly_wait(10)\n",
    "            browser.find_element(By.CSS_SELECTOR,'.enknx').click()\n",
    "            browser.find_element(By.CSS_SELECTOR,'.daMwF').click()\n",
    "            browser.find_element(By.CSS_SELECTOR,'.bKLYt > .duhwe > .pIRBV')\n",
    "            \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        pSource = soup(browser.page_source,'html.parser')\n",
    "        \n",
    "        Expect = \"None\"\n",
    "        Note = \"None\"\n",
    "\n",
    "        Travel_Safe_Section = pSource.find('div', class_ = 'ui_column is-12 fnAcQ fNRLc fvoLb _T MG')\n",
    "        if Travel_Safe_Section is not None:\n",
    "            Expect = Travel_Safe_Section.find('ul', class_ = 'fwFeg F1')\n",
    "            Note =  Travel_Safe_Section.find('div', class_ = 'pIRBV _T')            \n",
    "            Expect = re.sub('<[^<]+?>', ' ', str(Expect))\n",
    "            Note = re.sub('<[^<]+?>', ' ', str(Note))\n",
    "            \n",
    "        COVID_Expect.append(Expect)\n",
    "        COVID_Note.append(Note)\n",
    "\n",
    "        browser.close()\n",
    "    \n",
    "        \n",
    "    print('=========== Finished =========== ')\n",
    "    COVID_df = pd.DataFrame({\n",
    "        \"hotel name\": hotelNames,\n",
    "        \"hotel URL\": hotelURLs,\n",
    "        \"hotel ID\": hotelIDs,\n",
    "        \"travel safe expect\": COVID_Expect,\n",
    "        \"travel safe note\": COVID_Note\n",
    "    })\n",
    "\n",
    "    # export to csv\n",
    "    COVID_df.to_csv(outputName, index=False)\n",
    "    print(\"Saved \"+outputName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830429d0",
   "metadata": {
    "id": "830429d0",
    "outputId": "4389ac31-c581-4e43-c26c-57b8b5498579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Finished =========== \n",
      "Saved COVID_Msg_Quarantine.csv\n"
     ]
    }
   ],
   "source": [
    "scrape_COVID19('../data/HotelList_Quarantine.xlsx', 'hotels', '../output/COVID_Msg_Quarantine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545733e0",
   "metadata": {
    "id": "545733e0",
    "outputId": "7f5bcce5-8382-4940-a49f-02f2f7a95680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Finished =========== \n",
      "Saved COVID_Msg_NonQuarantine.csv\n"
     ]
    }
   ],
   "source": [
    "scrape_COVID19('../data/HotelList_NonQuarantine.xlsx', 'hotels', '../output/COVID_Msg_NonQuarantine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f232da02",
   "metadata": {
    "id": "f232da02"
   },
   "source": [
    "# Code for scraping individual reviews URL from each hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a5a63",
   "metadata": {
    "id": "cf1a5a63"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "\n",
    "df = pd.read_excel('../data/HotelList_Quarantine.xlsx', sheet_name='hotels')\n",
    "\n",
    "# NonQuarantine\n",
    "#df = pd.read_excel('HotelList_NonQuarantine.xlsx', sheet_name='hotels')\n",
    "\n",
    "################################################################################\n",
    "\n",
    "reviewURLs = []\n",
    "\n",
    "#scrape one by one\n",
    "#hotelURLs = [df['URL'][102]]\n",
    "\n",
    "#scrape several at one time\n",
    "#sometimes there are timeout problem in selenium, so scrape the data bit by bit instead of the whole list at once\n",
    "hotelURLs = df['URL'][99:102].tolist() \n",
    "\n",
    "for hotelURL in hotelURLs:\n",
    "\n",
    "    chromedriver_autoinstaller.install()  \n",
    "    browser = webdriver.Chrome()\n",
    "\n",
    "    browser.get(hotelURL) \n",
    "    \n",
    "    #scrape only those reviews with the words \"quarantine\"\n",
    "    elem = browser.find_element_by_css_selector('input.bozft')\n",
    "    elem.clear()\n",
    "    elem.send_keys(\"quarantine\") #hide when scraping non-quarantine reviews\n",
    "    elem.send_keys(Keys.RETURN)\n",
    "    elem.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Wait a some seconds for the page to completely load\n",
    "    sleep(5)\n",
    "    \n",
    "    elems = browser.find_elements(By.CSS_SELECTOR, \".fpMxB [href]\")\n",
    "    for elem in elems:   \n",
    "        browser.implicitly_wait(5)\n",
    "        links = elem.get_attribute('href')\n",
    "        reviewURLs.append(links)\n",
    "\n",
    "\n",
    "    # next page 2\n",
    "    browser.find_element(By.CSS_SELECTOR, '.next').click()\n",
    "    sleep(5)\n",
    "    \n",
    "    elems = ''\n",
    "    elems = browser.find_elements(By.CSS_SELECTOR, \".fpMxB [href]\")\n",
    "    for elem in elems:\n",
    "        browser.implicitly_wait(5)\n",
    "        links = ''\n",
    "        links = elem.get_attribute('href')\n",
    "        reviewURLs.append(links)\n",
    "    \n",
    "    # next page 3\n",
    "    browser.find_element(By.CSS_SELECTOR, '.next').click()\n",
    "    sleep(5)\n",
    "    \n",
    "    elems = ''\n",
    "    elems = browser.find_elements(By.CSS_SELECTOR, \".fpMxB [href]\")\n",
    "    for elem in elems:\n",
    "        browser.implicitly_wait(5)\n",
    "        links = ''\n",
    "        links = elem.get_attribute('href')\n",
    "        reviewURLs.append(links)\n",
    "\n",
    "    # etc.....repeat if needed\n",
    "  \n",
    "    reviews_all_urls = pd.DataFrame({\n",
    "        \"Review_URL\": reviewURLs\n",
    "    })\n",
    "\n",
    "    reviews_all_urls = reviews_all_urls.drop_duplicates()\n",
    "    \n",
    "    ################################################################################\n",
    "    \n",
    "    reviews_all_urls.to_csv('reviewsURLs_Quarantine.csv', mode='a', header=False, index=False)\n",
    "    #reviews_all_urls.to_csv('reviewsURLs_NonQuarantine.csv', mode='a', header=False, index=False)\n",
    "    \n",
    "    ################################################################################\n",
    "    \n",
    "    print('saved for ' + str(hotelURL))\n",
    "    \n",
    "    browser.close()\n",
    "\n",
    "print('============== Finished =================')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c84de",
   "metadata": {
    "id": "346c84de"
   },
   "source": [
    "# Code for scraping each customer review & hotel reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b58774",
   "metadata": {
    "id": "86b58774"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "\n",
    "df_r = pd.read_excel('../data/reviewsURLs_Quarantine.xlsx', sheet_name='reviewURLs')\n",
    "\n",
    "#NonQuarantine\n",
    "#df_r = pd.read_excel('../data/reviewsURLs_NonQuarantine.xlsx', sheet_name='reviewURLs')\n",
    "\n",
    "################################################################################\n",
    "\n",
    "### ============== try first two as example ===============\n",
    "\n",
    "# hotelIDs = df_r['HotelID'][0:3].tolist()\n",
    "# reviewIDs = df_r['ReviewID'][0:3].tolist()\n",
    "# reviewURLs = df_r['ReviewURL'][0:3].tolist()\n",
    "\n",
    "### ============== try first two as example ===============\n",
    "\n",
    "\n",
    "#### ================ run all ===============\n",
    "hotelIDs = df_r['HotelID']\n",
    "reviewIDs = df_r['ReviewID']\n",
    "reviewURLs = df_r['ReviewURL']\n",
    "userIDs = []\n",
    "customer_reviewTitles = []           \n",
    "customer_ratingDates = []   \n",
    "customer_ratings = [] \n",
    "customer_comments = []      \n",
    "hotelReply = []             \n",
    "hotelReply_comments = []    \n",
    "hotelReply_dates = [] \n",
    "\n",
    "\n",
    "\n",
    "for reviewURL in reviewURLs:\n",
    "    \n",
    "    chromedriver_autoinstaller.install()  \n",
    "    browser = webdriver.Chrome()\n",
    "    \n",
    "    browser.get(reviewURL)\n",
    "    \n",
    "    try:\n",
    "        # click \"more\" to show all the comment text and hotel reply\n",
    "        browser.find_element(By.CSS_SELECTOR,'.moreBtn').click()\n",
    "        browser.implicitly_wait(10)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        \n",
    "    pSource = soup(browser.page_source,'html.parser')\n",
    "    reviewContent = pSource.find('div', class_ = 'featured-review-container')\n",
    "    \n",
    "    # userID\n",
    "    userID = reviewContent.find('div', id=re.compile('^UID'))\n",
    "    userIDs.append(userID)\n",
    "    \n",
    "    \n",
    "    # customer_reviewTitles\n",
    "    customer_reviewTitle = reviewContent.find(id='HEADING').getText()\n",
    "    customer_reviewTitles.append(customer_reviewTitle)\n",
    "    \n",
    "    \n",
    "    # customer_ratingDates\n",
    "    customer_ratingDate = reviewContent.find('span', class_ = 'ratingDate').getText()\n",
    "    customer_ratingDates.append(customer_ratingDate)\n",
    "    \n",
    "    # customer_ratings\n",
    "    customer_rating = reviewContent.find('span', class_ = 'ui_bubble_rating').get('class')[1]\n",
    "    customer_ratings.append(customer_rating)\n",
    "    \n",
    "    # customer_comments\n",
    "    customer_comment = reviewContent.find('span', class_ = 'fullText').getText()\n",
    "    customer_comments.append(customer_comment)\n",
    "    \n",
    "    \n",
    "    # hotelReply_comments & hotelReply\n",
    "    hotelReply_comment = reviewContent.find('div', class_ = 'prw_reviews_text_summary_hsx')\n",
    "    if hotelReply_comment is not None:\n",
    "        hotelReply_comment = hotelReply_comment.getText()\n",
    "        hotelReply_comments.append(hotelReply_comment)\n",
    "        hotelReply.append('1')\n",
    "    else:\n",
    "        hotelReply_comments.append('NaN')\n",
    "        hotelReply.append('0')\n",
    "    \n",
    "    \n",
    "    # hotelReply_dates\n",
    "    hotelReply_date = reviewContent.find('span', class_ = 'responseDate')\n",
    "    if hotelReply_date is not None:\n",
    "        hotelReply_date = hotelReply_date.getText()\n",
    "        hotelReply_dates.append(hotelReply_date)\n",
    "    else:\n",
    "        hotelReply_dates.append('NaN')\n",
    "    \n",
    "    \n",
    "    \n",
    "    browser.close()\n",
    "    \n",
    "print('=========== Finished =========== ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c0d01",
   "metadata": {
    "id": "1b5c0d01"
   },
   "outputs": [],
   "source": [
    "scraped = pd.DataFrame({\n",
    "    \"UserID\": userIDs,\n",
    "    \"hotel ID\": hotelIDs,\n",
    "    \"review ID\": reviewIDs,\n",
    "    \"review URL\": reviewURLs,\n",
    "    \"customer review Title\": customer_reviewTitles,      \n",
    "    \"customer review date\": customer_ratingDates,   \n",
    "    \"customer review score\": customer_ratings, \n",
    "    \"customer review text\": customer_comments,  \n",
    "    \"hotel reply yes or no\": hotelReply,    \n",
    "    \"hotel reply text\": hotelReply_comments,\n",
    "    \"hotel reply date\": hotelReply_dates   \n",
    "})\n",
    "\n",
    "scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674219e",
   "metadata": {
    "id": "e674219e"
   },
   "outputs": [],
   "source": [
    "# export to csv\n",
    "scraped.to_csv(\"../output/data_Quarantine_needClean.csv\",encoding='utf-8-sig')\n",
    "\n",
    "#NonQuarantine\n",
    "#scraped.to_csv(\"data_NonQuarantine_needClean.csv\",encoding='utf-8-sig')\n",
    "print(\"Saved.\")\n",
    "\n",
    "### Then, manually do the data cleaning and filtering. \n",
    "#E.g. remove Chinese reviews, remove reviews that are in 2022 and those before Mar 2020, etc.\n",
    "#Final cleaned dataset \"../data/data_NonQuarantine.xlsx\" & \"../data/data_Quarantine.xlsx\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1_dataCollection_Scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
